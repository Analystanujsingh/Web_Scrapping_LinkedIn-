{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import gspread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from google.auth import exceptions\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.service_account import Credentials\n",
    "from google.oauth2 import service_account\n",
    "from gspread_dataframe import set_with_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linkedin URL \n",
    "\n",
    "url='link to your linkedin link'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# automated and open URL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_driver_path = r'' # chrome driver path\n",
    "\n",
    "# Chrome service with the specified executable path\n",
    "chrome_service = Service(chrome_driver_path)\n",
    "\n",
    "# Initialize the Chrome driver using the Chrome service\n",
    "driver = webdriver.Chrome(service=chrome_service)\n",
    "driver.implicitly_wait(10)\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find number of job listings\n",
    "job_count_element = driver.find_element(By.CLASS_NAME, 'results-context-header__job-count') # count the job list\n",
    "job_count_text = job_count_element.text\n",
    "print(\"Number of job listings:\", job_count_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type casting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(job_count_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-numeric characters\n",
    "cleaned_text = ''.join(filter(str.isdigit, job_count_text))\n",
    "\n",
    "# Convert to numeric\n",
    "n = pd.to_numeric(cleaned_text)\n",
    "\n",
    "print(\"Number of job listings (numeric):\", n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implemented automated infinite scrolling and a custom button-based job list filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom limit for the number of clicks\n",
    "\n",
    "custom_click_limit = 30\n",
    "\n",
    "i = 2\n",
    "while i <= custom_click_limit:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") # for scrolling\n",
    "    time.sleep(2)\n",
    "\n",
    "    try:\n",
    "        btn = driver.find_element(By.XPATH, \"//button[@aria-label='See more jobs']\") # click button\n",
    "        driver.execute_script(\"arguments[0].click();\", btn)\n",
    "        print(f\"Clicked 'See more jobs' button {i - 1} times.\")\n",
    "        time.sleep(2)  # short pause after clicking the button\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        print(\"No more 'See more jobs' button found. Exiting loop.\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        time.sleep(3)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "print(\"Number of times 'See more jobs' button was clicked:\", i - 2 if i > 2 else 0)\n",
    "\n",
    "# give time for the new jobs to load\n",
    "time.sleep(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lists to store job details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store job details\n",
    "\n",
    "company_names = []\n",
    "job_titles = []\n",
    "job_locations = []\n",
    "job_post_urls = []\n",
    "Job_Salary = []\n",
    "Job_Info = []\n",
    "Job_ListTime = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping data from Linkedin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scraping data with minimum lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code will iteratively scrape job listings and populate a storage list until it encounters a terminating condition indicated by None values\n",
    "\n",
    "try:\n",
    "    for i in range(n):\n",
    "        # Use find_elements instead of find_element to get a list of elements\n",
    "        company_name_elements = driver.find_elements(By.CLASS_NAME, 'base-search-card__subtitle')\n",
    "        job_title_elements = driver.find_elements(By.CLASS_NAME, 'base-search-card__title')\n",
    "        job_location_elements = driver.find_elements(By.CLASS_NAME, 'job-search-card__location')\n",
    "        job_post_url_elements = driver.find_elements(By.CSS_SELECTOR, 'a.base-card__full-link')\n",
    "        job_salary_elements = driver.find_elements(By.CLASS_NAME, 'job-search-card__salary-info')\n",
    "        job_info_elements = driver.find_elements(By.CLASS_NAME, 'result-benefits__text')\n",
    "        list_time_elements = driver.find_elements(By.CLASS_NAME, 'job-search-card__listdate')\n",
    "\n",
    "        # Extract data for 'Company Name'\n",
    "        company_name_data = [element.text if i < len(company_name_elements) else \"None\" for i, element in enumerate(company_name_elements)]\n",
    "        company_names.extend(company_name_data)\n",
    "\n",
    "        # Extract data for 'Job Title'\n",
    "        job_title_data = [element.text if i < len(job_title_elements) else \"None\" for i, element in enumerate(job_title_elements)]\n",
    "        job_titles.extend(job_title_data)\n",
    "\n",
    "        # Extract data for 'Job Location'\n",
    "        job_location_data = [element.text if i < len(job_location_elements) else \"None\" for i, element in enumerate(job_location_elements)]\n",
    "        job_locations.extend(job_location_data)\n",
    "\n",
    "        # Extract data for 'Job Post URL'\n",
    "        job_post_url_data = [element.get_attribute('href') if i < len(job_post_url_elements) else \"None\" for i, element in enumerate(job_post_url_elements)]\n",
    "        job_post_urls.extend(job_post_url_data)\n",
    "\n",
    "        # Extract data for 'Job Salary'\n",
    "        job_salary_data = [element.text if i < len(job_salary_elements) else \"None\" for i, element in enumerate(job_salary_elements)]\n",
    "        Job_Salary.extend(job_salary_data)\n",
    "\n",
    "        # Extract data for 'Job Info'\n",
    "        job_info_data = [element.text if i < len(job_info_elements) else \"None\" for i, element in enumerate(job_info_elements)]\n",
    "        Job_Info.extend(job_info_data)\n",
    "\n",
    "        # Extract data for 'List Time'\n",
    "        list_time_data = [element.get_attribute('datetime') if i < len(list_time_elements) else \"None\" for i, element in enumerate(list_time_elements)]\n",
    "        Job_ListTime.extend(list_time_data)\n",
    "    \n",
    "except IndexError:\n",
    "    print(\"Error: Index out of range. There may be an issue with the number of jobs loaded.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while extracting job details: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Check if all lists have the same length\n",
    "    min_length = min(len(company_names), len(job_titles), len(job_locations), len(job_post_urls), len(Job_Salary), len(Job_Info), len(Job_ListTime))\n",
    "\n",
    "    # Trim lists to the minimum length\n",
    "    company_names = company_names[:min_length]\n",
    "    job_titles = job_titles[:min_length]\n",
    "    job_locations = job_locations[:min_length]\n",
    "    job_post_urls = job_post_urls[:min_length]\n",
    "    Job_Salary = Job_Salary[:min_length]\n",
    "    Job_Info = Job_Info[:min_length]\n",
    "    Job_ListTime = Job_ListTime[:min_length]\n",
    "\n",
    "    # Proceed to create DataFrame\n",
    "    data = {\n",
    "        'Company Name': company_names,\n",
    "        'Job Title': job_titles,\n",
    "        'Location': job_locations,\n",
    "        'Job Post URL': job_post_urls,\n",
    "        'Salary': Job_Salary,\n",
    "        'Job Info': Job_Info,\n",
    "        'List Time': Job_ListTime\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scraping job list with maximum lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code will iteratively scrape job listings and populate a storage list until it encounters a terminating condition indicated by None values\n",
    "\n",
    "try:\n",
    "    for i in range(n):\n",
    "        # Use find_elements instead of find_element to get a list of elements\n",
    "        company_name_elements = driver.find_elements(By.CLASS_NAME, 'base-search-card__subtitle')\n",
    "        job_title_elements = driver.find_elements(By.CLASS_NAME, 'base-search-card__title')\n",
    "        job_location_elements = driver.find_elements(By.CLASS_NAME, 'job-search-card__location')\n",
    "        job_post_url_elements = driver.find_elements(By.CSS_SELECTOR, 'a.base-card__full-link')\n",
    "        job_salary_elements = driver.find_elements(By.CLASS_NAME, 'job-search-card__salary-info')\n",
    "        job_info_elements = driver.find_elements(By.CLASS_NAME, 'result-benefits__text')\n",
    "        list_time_elements = driver.find_elements(By.CLASS_NAME, 'job-search-card__listdate')\n",
    "\n",
    "        # Extract data for 'Company Name'\n",
    "        company_name_data = [element.text if i < len(company_name_elements) else \"None\" for i, element in enumerate(company_name_elements)]\n",
    "        company_names.extend(company_name_data)\n",
    "\n",
    "        # Extract data for 'Job Title'\n",
    "        job_title_data = [element.text if i < len(job_title_elements) else \"None\" for i, element in enumerate(job_title_elements)]\n",
    "        job_titles.extend(job_title_data)\n",
    "\n",
    "        # Extract data for 'Job Location'\n",
    "        job_location_data = [element.text if i < len(job_location_elements) else \"None\" for i, element in enumerate(job_location_elements)]\n",
    "        job_locations.extend(job_location_data)\n",
    "\n",
    "        # Extract data for 'Job Post URL'\n",
    "        job_post_url_data = [element.get_attribute('href') if i < len(job_post_url_elements) else \"None\" for i, element in enumerate(job_post_url_elements)]\n",
    "        job_post_urls.extend(job_post_url_data)\n",
    "\n",
    "        # Extract data for 'Job Salary'\n",
    "        job_salary_data = [element.text if i < len(job_salary_elements) else \"None\" for i, element in enumerate(job_salary_elements)]\n",
    "        Job_Salary.extend(job_salary_data)\n",
    "\n",
    "        # Extract data for 'Job Info'\n",
    "        job_info_data = [element.text if i < len(job_info_elements) else \"None\" for i, element in enumerate(job_info_elements)]\n",
    "        Job_Info.extend(job_info_data)\n",
    "\n",
    "        # Extract data for 'List Time'\n",
    "        list_time_data = [element.get_attribute('datetime') if i < len(list_time_elements) else \"None\" for i, element in enumerate(list_time_elements)]\n",
    "        Job_ListTime.extend(list_time_data)\n",
    "    \n",
    "except IndexError:\n",
    "    print(\"Error: Index out of range. There may be an issue with the number of jobs loaded.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while extracting job details: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Trim all lists to the length of the longest list\n",
    "    max_length = max(len(company_names), len(job_titles), len(job_locations), len(job_post_urls), len(Job_Salary), len(Job_Info), len(Job_ListTime))\n",
    "\n",
    "    company_names = company_names + [\"None\"] * (max_length - len(company_names))\n",
    "    job_titles = job_titles + [\"None\"] * (max_length - len(job_titles))\n",
    "    job_locations = job_locations + [\"None\"] * (max_length - len(job_locations))\n",
    "    job_post_urls = job_post_urls + [\"None\"] * (max_length - len(job_post_urls))\n",
    "    Job_Salary = Job_Salary + [\"None\"] * (max_length - len(Job_Salary))\n",
    "    Job_Info = Job_Info + [\"None\"] * (max_length - len(Job_Info))\n",
    "    Job_ListTime = Job_ListTime + [\"None\"] * (max_length - len(Job_ListTime))\n",
    "\n",
    "    # Proceed to create DataFrame\n",
    "    data = {\n",
    "        'Company Name': company_names,\n",
    "        'Job Title': job_titles,\n",
    "        'Location': job_locations,\n",
    "        'Job Post URL': job_post_urls,\n",
    "        'Salary': Job_Salary,\n",
    "        'Job Info': Job_Info,\n",
    "        'List Time': Job_ListTime\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizing the Google Sheets API to programmatically transfer a DataFrame's contents to a Google Sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### go to gooogle cloud and then create new project. create service account and in tab theres key tab and then create json key and copy that json path and get the client email from that json file and connect it with spreadsheet and enable google sheet & drive API and you're ready to run below code that will connect dataframe to spreadsheet directly with spreadsheet link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Google API\n",
    "scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/drive\"] \n",
    "# Credentials file in JSON format for accessing Google Sheets APIs\n",
    "creds = Credentials.from_service_account_file(r'path of JSON key', scopes=scope)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "# Google Spreadsheet Link \n",
    "spreadsheet = client.open_by_url('link to your spreadsheet')\n",
    "\n",
    "#spreadsheet = client.open(\"name of your spreadsheet\") # open by spreadsheet name\n",
    "worksheet = spreadsheet.get_worksheet(0)  # first worksheet in the spreadsheet\n",
    "\n",
    "# Clear existing data in the sheet\n",
    "worksheet.clear()\n",
    "\n",
    "# Write the DataFrame to the Google Sheet\n",
    "set_with_dataframe(worksheet, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Close the WebDriver\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# thanks (❁´◡`❁)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
